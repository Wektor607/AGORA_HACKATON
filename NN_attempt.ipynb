{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "scaler = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t = pd.read_csv('train.csv')\n",
    "val_t = pd.read_csv('val.csv')\n",
    "test_t = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007302f2fe1d54d</td>\n",
       "      <td>f497219eb0077f84</td>\n",
       "      <td>Классическая сплит-система ROYAL CLIMA PANDORA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0039af5efceac4ab</td>\n",
       "      <td>28085e941cde1639</td>\n",
       "      <td>Холодильник Бирюса 118. Мощность  замораживани...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004f2158acb8165c</td>\n",
       "      <td>9afe55bb4bf1e8a8</td>\n",
       "      <td>ASUS TUF-GTX1660S-O6G-GAMING Видеокарта. Объем...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005cddb29e1677ec</td>\n",
       "      <td>1f21918ceb5d345c</td>\n",
       "      <td>Кофемашина Saeco Lirika One Touch Cappuccino, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0083dddef6bc6503</td>\n",
       "      <td>8f9c8fcf9cb2862c</td>\n",
       "      <td>Lenovo 62A8KAT1EU Монитор. Яркость 250   кд/м²...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>fa06227ed7b42bba</td>\n",
       "      <td>79365b00febf391b</td>\n",
       "      <td>Посудомоечная машина Weissgauff BDW 4004. Тайм...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>fa3b915603e2839e</td>\n",
       "      <td>13a23947cc15cfe7</td>\n",
       "      <td>Монитор Xiaomi Mi Desktop Monitor 27'' RMMNT27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>fc7ac235b0c1149c</td>\n",
       "      <td>b435b4515808e799</td>\n",
       "      <td>Холодильник GA-B379SLUL LG. Общий объем 261 л....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>feb6f146f3be1ccb</td>\n",
       "      <td>8e2012bfdbccf188</td>\n",
       "      <td>Водонагреватель ariston накопительный водонагр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>ff75ade409f4da7e</td>\n",
       "      <td>177ccb3b84125efa</td>\n",
       "      <td>Huawei Умный браслет Band 7, графитово-черный....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1817 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            product_id      reference_id  \\\n",
       "0     0007302f2fe1d54d  f497219eb0077f84   \n",
       "1     0039af5efceac4ab  28085e941cde1639   \n",
       "2     004f2158acb8165c  9afe55bb4bf1e8a8   \n",
       "3     005cddb29e1677ec  1f21918ceb5d345c   \n",
       "4     0083dddef6bc6503  8f9c8fcf9cb2862c   \n",
       "...                ...               ...   \n",
       "1812  fa06227ed7b42bba  79365b00febf391b   \n",
       "1813  fa3b915603e2839e  13a23947cc15cfe7   \n",
       "1814  fc7ac235b0c1149c  b435b4515808e799   \n",
       "1815  feb6f146f3be1ccb  8e2012bfdbccf188   \n",
       "1816  ff75ade409f4da7e  177ccb3b84125efa   \n",
       "\n",
       "                                                 merged  \n",
       "0     Классическая сплит-система ROYAL CLIMA PANDORA...  \n",
       "1     Холодильник Бирюса 118. Мощность  замораживани...  \n",
       "2     ASUS TUF-GTX1660S-O6G-GAMING Видеокарта. Объем...  \n",
       "3     Кофемашина Saeco Lirika One Touch Cappuccino, ...  \n",
       "4     Lenovo 62A8KAT1EU Монитор. Яркость 250   кд/м²...  \n",
       "...                                                 ...  \n",
       "1812  Посудомоечная машина Weissgauff BDW 4004. Тайм...  \n",
       "1813  Монитор Xiaomi Mi Desktop Monitor 27'' RMMNT27...  \n",
       "1814  Холодильник GA-B379SLUL LG. Общий объем 261 л....  \n",
       "1815  Водонагреватель ariston накопительный водонагр...  \n",
       "1816  Huawei Умный браслет Band 7, графитово-черный....  \n",
       "\n",
       "[1817 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train = train_t#.append(val_t)\n",
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1817, 409, 2226)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_t), len(val_t), len(train_t) + len(val_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Val = val_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = test_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Train['merged'].to_numpy()\n",
    "X_val = Val['merged'].to_numpy()\n",
    "X_test = Test['merged'].to_numpy()\n",
    "\n",
    "y_train = Train['reference_id'].to_numpy()\n",
    "y_val = Val['reference_id'].to_numpy()\n",
    "y_test = Test['reference_id'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = {i: k for k, i in enumerate(np.unique(y_train))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\setuptools\\distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Optional\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.utils import make_grid\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Версия без испльзования описания эталонов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 X,\n",
    "                 y,\n",
    "                 scaler = scaler,\n",
    "                 encoder = encoder\n",
    "                ):\n",
    "        ## list of tuples: (img, label)\n",
    "        self._items = []\n",
    "        self.scaler = scaler\n",
    "        self.encoder = encoder\n",
    "        for (text, label) in zip(self.scaler.transform(X).toarray(), y):\n",
    "            self._items.append((text, self.encoder[label]))        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._items)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text, label = self._items[index]\n",
    "\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = MyCustomDataset(X_train, y_train)\n",
    "ds_val = MyCustomDataset(X_val, y_val)\n",
    "ds_test = MyCustomDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3657"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train[0][0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1817, 409, 554)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_train), len(ds_val), len(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train, batch_size=32, shuffle=True, num_workers=0)\n",
    "dl_val = DataLoader(ds_val, batch_size=32, shuffle=False, num_workers=0)\n",
    "dl_test = DataLoader(ds_test, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(pl.LightningModule):\n",
    "    # REQUIRED\n",
    "    def __init__(self, input_shape=ds_train[0][0].shape[0], test_data=dl_test, num_classes=len(encoder.keys())):\n",
    "        super().__init__()\n",
    "        \"\"\" Define computations here. \"\"\"\n",
    "        \n",
    "        # Описываем модель\n",
    "        self.fc1 = nn.Linear(input_shape, 2048)\n",
    "        self.act1 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.drop1 = nn.Dropout(p=0.7)\n",
    "        self.fc2 = nn.Linear(2048, 512)\n",
    "        self.act2 = nn.LeakyReLU(negative_slope=0.05)\n",
    "        self.drop2 = nn.Dropout(p=0.5)\n",
    "        self.fc3 = nn.Linear(512, num_classes)\n",
    "        \n",
    "        # Для оценки качества на тестовых данных можем указать \n",
    "        # сразу данные, на которых и будет производиться эта оценка\n",
    "        self.test_data = test_data\n",
    "        \n",
    "        # В качестве ошибки выступает кросс-энтропия\n",
    "        self.loss = F.cross_entropy\n",
    "        \n",
    "        # Дополнительно посмотрим на метрику точности, т.к. она более понятна\n",
    "        self.accuracy = lambda x, y: (x.argmax(-1) == y).float().mean()\n",
    "    \n",
    "    # REQUIRED\n",
    "    def forward(self, x):\n",
    "        \"\"\" Use for inference only (separate from training_step). \"\"\"\n",
    "        # Чтобы избежать ошибок, переводим данные в нужный формат\n",
    "        x = x.type(torch.FloatTensor)\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.type(torch.cuda.FloatTensor)\n",
    "        \n",
    "        # Описываем поведение сети, т.е. как она проходит \n",
    "        # через 1-ый слой, \n",
    "        x = self.drop1(self.act1(self.fc1(x)))\n",
    "        # применяем функцию-срезку\n",
    "        x = self.drop2(self.act2(self.fc2(x)))\n",
    "        \n",
    "        #x = self.drop3(self.act3(self.fc3(x)))\n",
    "        # применяем второй слой\n",
    "        x = self.fc3(x)\n",
    "    \n",
    "        return x\n",
    "    \n",
    "    # REQUIRED -- в конце каждого этапа обучения будут сохраняться результаты \n",
    "    # ошибок и точности на данной эпохе для обуающей выборки\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"the full training loop\"\"\"\n",
    "        x, y = batch\n",
    "        \n",
    "        x = x.type(torch.FloatTensor)\n",
    "        y = y.type(torch.LongTensor)\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.type(torch.cuda.FloatTensor)\n",
    "            y = y.type(torch.cuda.LongTensor)\n",
    "\n",
    "        y_logit = self(x)\n",
    "        loss = self.loss(y_logit, y)\n",
    "        \n",
    "        acc = self.accuracy(y_logit, y)\n",
    "\n",
    "        return {'loss': loss, 'acc': acc}\n",
    "\n",
    "    # REQUIRED -- определяем оптимизатор и задаем learning rate\n",
    "    # P.s. еще можно указать как менять скорость обучения, \n",
    "    #      но тут мало эпох и слишком простая задача для этого\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\" Define optimizers and LR schedulers. \"\"\"\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        \n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                                  mode='min', \n",
    "                                                                  factor=0.2, \n",
    "                                                                  patience=2, \n",
    "                                                                  verbose=True)\n",
    "        \n",
    "        lr_dict = {\n",
    "            # REQUIRED: The scheduler instance\n",
    "            \"scheduler\": lr_scheduler,\n",
    "            # The unit of the scheduler's step size, could also be 'step'.\n",
    "            # 'epoch' updates the scheduler on epoch end whereas 'step'\n",
    "            # updates it after a optimizer update.\n",
    "            \"interval\": \"epoch\",\n",
    "            # How many epochs/steps should pass between calls to\n",
    "            # `scheduler.step()`. 1 corresponds to updating the learning\n",
    "            # rate after every epoch/step.\n",
    "            \"frequency\": 1,\n",
    "            # Metric to to monitor for schedulers like `ReduceLROnPlateau`\n",
    "            \"monitor\": \"val_loss\"\n",
    "        } \n",
    "        \n",
    "        return [optimizer], [lr_dict]\n",
    "    \n",
    "    # OPTIONAL -- как и с обучающими, но тут результаты на валидации, чтобы отслеживать переобучение\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"the full validation loop\"\"\"\n",
    "        x, y = batch\n",
    "\n",
    "        x = x.type(torch.FloatTensor)\n",
    "        y = y.type(torch.LongTensor)\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.type(torch.cuda.FloatTensor)\n",
    "            y = y.type(torch.cuda.LongTensor)\n",
    "            \n",
    "        y_logit = self(x)\n",
    "        loss = self.loss(y_logit, y)\n",
    "        \n",
    "        acc = self.accuracy(y_logit, y)\n",
    "\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "\n",
    "    # OPTIONAL -- как раз визуализация среднего значения результатов на обучающей выборке\n",
    "    def training_epoch_end(self, outputs):\n",
    "        \"\"\"log and display average train loss and accuracy across epoch\"\"\"\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['acc'] for x in outputs]).mean()\n",
    "        \n",
    "        print(f\"| Train_acc: {avg_acc:.2f}, Train_loss: {avg_loss:.2f}\" )\n",
    "        \n",
    "        self.log('train_loss', avg_loss, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        self.log('train_acc', avg_acc, prog_bar=True, on_epoch=True, on_step=False)\n",
    "     \n",
    "    # OPTIONAL -- то же самое для валидации\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        \"\"\"log and display average val loss and accuracy\"\"\"\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "        \n",
    "        print(f\"[Epoch {self.trainer.current_epoch:3}] Val_loss: {avg_loss:.5f} Val_accuracy: {avg_acc:.5f}\", end= \" \")\n",
    "        \n",
    "        self.log('val_loss', avg_loss, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        self.log('val_acc', avg_acc, prog_bar=True, on_epoch=True, on_step=False)\n",
    "    \n",
    "    # Оценка качества на тестовой выборке\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss(logits, y)\n",
    "        acc = self.accuracy(logits, y)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", acc, prog_bar=True)\n",
    "        \n",
    "    # Какие данные сеть полагает тестовыми\n",
    "    def test_dataloader(self):\n",
    "        return self.test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=15,\n",
    "    gpus=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type      | Params\n",
      "------------------------------------\n",
      "0 | fc1   | Linear    | 7.5 M \n",
      "1 | act1  | LeakyReLU | 0     \n",
      "2 | drop1 | Dropout   | 0     \n",
      "3 | fc2   | Linear    | 1.0 M \n",
      "4 | act2  | LeakyReLU | 0     \n",
      "5 | drop2 | Dropout   | 0     \n",
      "6 | fc3   | Linear    | 241 K \n",
      "------------------------------------\n",
      "8.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 M     Total params\n",
      "35.129    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   0] Val_loss: 6.15321 Val_accuracy: 0.01562 "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5e59f2f42894fde9688f1efff5485b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   0] Val_loss: 5.91198 Val_accuracy: 0.06798 | Train_acc: 0.02, Train_loss: 6.14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   1] Val_loss: 4.50922 Val_accuracy: 0.15385 | Train_acc: 0.05, Train_loss: 5.59\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   2] Val_loss: 2.92632 Val_accuracy: 0.30317 | Train_acc: 0.11, Train_loss: 4.23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   3] Val_loss: 2.15017 Val_accuracy: 0.47279 | Train_acc: 0.24, Train_loss: 3.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   4] Val_loss: 1.56030 Val_accuracy: 0.65779 | Train_acc: 0.40, Train_loss: 2.29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   5] Val_loss: 1.11559 Val_accuracy: 0.78067 | Train_acc: 0.58, Train_loss: 1.64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   6] Val_loss: 0.84747 Val_accuracy: 0.79577 | Train_acc: 0.68, Train_loss: 1.20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   7] Val_loss: 0.62193 Val_accuracy: 0.86615 | Train_acc: 0.78, Train_loss: 0.87\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   8] Val_loss: 0.48436 Val_accuracy: 0.89875 | Train_acc: 0.85, Train_loss: 0.61\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   9] Val_loss: 0.42263 Val_accuracy: 0.90221 | Train_acc: 0.89, Train_loss: 0.45\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  10] Val_loss: 0.35215 Val_accuracy: 0.91798 | Train_acc: 0.92, Train_loss: 0.35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  11] Val_loss: 0.33289 Val_accuracy: 0.90904 | Train_acc: 0.93, Train_loss: 0.27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  12] Val_loss: 0.31165 Val_accuracy: 0.91865 | Train_acc: 0.94, Train_loss: 0.23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  13] Val_loss: 0.25673 Val_accuracy: 0.92587 | Train_acc: 0.97, Train_loss: 0.17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  14] Val_loss: 0.24211 Val_accuracy: 0.93788 | Train_acc: 0.96, Train_loss: 0.15\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(m, dl_train, dl_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /mnt/d/AgoraHack/lightning_logs/version_33/checkpoints/epoch=14-step=855.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /mnt/d/AgoraHack/lightning_logs/version_33/checkpoints/epoch=14-step=855.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e464c66324249bc9f3ef590a5e81f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.9187725782394409\n",
      "        test_loss            0.294485867023468\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.294485867023468, 'test_acc': 0.9187725782394409}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SiamsNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcLoss(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(ArcLoss, self).__init__()\n",
    "        self.s = 30.0\n",
    "        self.m = 0.4\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.fc = nn.Linear(in_features, out_features, bias=False)\n",
    "        self.eps = 1e-7\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        for W in self.fc.parameters():\n",
    "            W = F.normalize(W, p=2, dim=1)\n",
    "        x = F.normalize(x, p=2, dim=1)\n",
    "        cos_theta = self.fc(x)\n",
    "        \n",
    "        numerator = cos_theta.transpose(0, 1)\n",
    "        numerator = torch.diagonal(numerator[labels])\n",
    "        numerator = torch.clamp(numerator, -1+self.eps, 1-self.eps)\n",
    "        numerator = self.s*torch.cos(torch.acos(numerator)+self.m)\n",
    "        \n",
    "        excluded_real_class = torch.cat([\n",
    "            torch.cat([cos_theta[i, :y], cos_theta[i, y+1:]])[None, :]\n",
    "            for i, y in enumerate(labels)\n",
    "        ], dim=0)\n",
    "        denominator = torch.exp(numerator) + torch.sum(torch.exp(self.s*excluded_real_class), dim=1)\n",
    "        \n",
    "        loss = numerator - torch.log(denominator)\n",
    "        return cos_theta, -loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcNet(pl.LightningModule):\n",
    "    def __init__(self, emb_net, train_classes):\n",
    "        super().__init__()\n",
    "        self.emb_net = emb_net\n",
    "        self.classifier = ArcLoss(512, train_classes)\n",
    "\n",
    "    def forward(self, x, cudaaa = True):\n",
    "        x = x.type(torch.FloatTensor)\n",
    "        if cudaaa and torch.cuda.is_available():\n",
    "            x = x.type(torch.cuda.FloatTensor)\n",
    "        \n",
    "        output = self.emb_net(x)\n",
    "        output = self.classifier(output)\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        x = x.type(torch.FloatTensor)\n",
    "        y = y.type(torch.LongTensor)\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.type(torch.cuda.FloatTensor)\n",
    "            y = y.type(torch.cuda.LongTensor)\n",
    "            \n",
    "        outputs = self.emb_net(x)\n",
    "        outputs, loss = self.classifier(outputs, y)\n",
    "        acc = (outputs.argmax(dim=1) == y).sum().item() / len(outputs)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        self.log('train_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self, input_shape=ds_train[0][0].shape[0]):\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_shape, 2048),\n",
    "            nn.LeakyReLU(negative_slope=0.3),\n",
    "            nn.Dropout(p=0.6),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.LeakyReLU(negative_slope=0.15),\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(1024, 512)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, cudaaa = True):\n",
    "        x = x.type(torch.FloatTensor)\n",
    "        if cudaaa and torch.cuda.is_available():\n",
    "            x = x.type(torch.cuda.FloatTensor)\n",
    "            \n",
    "        output = self.net(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_knn(emb_net, is_normalize=False):\n",
    "    data_x = []\n",
    "    data_y = []\n",
    "    with torch.no_grad():\n",
    "        for data in dl_train:\n",
    "            inputs, labels = data[0], data[1]\n",
    "            feats = emb_net(inputs, cudaaa=False).detach().cpu().numpy()\n",
    "            \n",
    "            data_x.append(feats)\n",
    "            data_y.append(labels)\n",
    "    data_x = np.concatenate(data_x, axis=0)\n",
    "    data_y = np.concatenate(data_y, axis=0)\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=1, metric='cosine') #512 -> 1 эталон -- предложение -> NeuralNet[3657 -> 512] Knn[512 -> 1] эталон\n",
    "    knn = knn.fit(data_x, data_y)\n",
    "    \n",
    "    return knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_knn(emb_net, knn, is_normalize=False):\n",
    "    total_correct = 0\n",
    "    total_cnt = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dl_test:\n",
    "            inputs, labels = data[0], data[1].detach().cpu().numpy()\n",
    "            feats = emb_net(inputs, cudaaa=False).detach().cpu().numpy()\n",
    "            preds = knn.predict(feats)\n",
    "            \n",
    "            total_correct += (preds == labels).sum()\n",
    "            total_cnt += len(preds)\n",
    "    \n",
    "    acc = total_correct/total_cnt\n",
    "    print(f'Accuracy = {acc*100}%')\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_train_dl = DataLoader(ds_train, 32, num_workers=0)\n",
    "arc_val_dl = DataLoader(dl_val, 32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/rw/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:131: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "  rank_zero_warn(\"You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type         | Params\n",
      "--------------------------------------------\n",
      "0 | emb_net    | EmbeddingNet | 10.1 M\n",
      "1 | classifier | ArcLoss      | 241 K \n",
      "--------------------------------------------\n",
      "10.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.4 M    Total params\n",
      "41.423    Total estimated model params size (MB)\n",
      "/home/rw/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b9a7e802024daf83d9968722bf1986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net_arc = ArcNet(EmbeddingNet(), train_classes=len(encoder.keys()))\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=5)\n",
    "trainer.fit(net_arc, arc_train_dl, arc_val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 82.12996389891697%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8212996389891697"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_arc.eval()\n",
    "net_arc.emb_net.to('cpu')\n",
    "knn = train_knn(net_arc.emb_net, is_normalize=True)\n",
    "test_knn(net_arc.emb_net, knn, is_normalize=True) # RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 94.22382671480143%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9422382671480144"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_arc.eval()\n",
    "net_arc.emb_net.to('cpu')\n",
    "knn = train_knn(net_arc.emb_net, is_normalize=True)\n",
    "test_knn(net_arc.emb_net, knn, is_normalize=True) #KNN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 93.14079422382672%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9314079422382672"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_arc.eval()\n",
    "net_arc.emb_net.to('cpu')\n",
    "knn = train_knn(net_arc.emb_net, is_normalize=True)\n",
    "test_knn(net_arc.emb_net, knn, is_normalize=True) #KNN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 93.14079422382672%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9314079422382672"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_arc.eval()\n",
    "net_arc.emb_net.to('cpu')\n",
    "knn = train_knn(net_arc.emb_net, is_normalize=True)\n",
    "test_knn(net_arc.emb_net, knn, is_normalize=True) #KNN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007302f2fe1d54d</td>\n",
       "      <td>f497219eb0077f84</td>\n",
       "      <td>Классическая сплит-система ROYAL CLIMA PANDORA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0039af5efceac4ab</td>\n",
       "      <td>28085e941cde1639</td>\n",
       "      <td>Холодильник Бирюса 118. Мощность  замораживани...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004f2158acb8165c</td>\n",
       "      <td>9afe55bb4bf1e8a8</td>\n",
       "      <td>ASUS TUF-GTX1660S-O6G-GAMING Видеокарта. Объем...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005cddb29e1677ec</td>\n",
       "      <td>1f21918ceb5d345c</td>\n",
       "      <td>Кофемашина Saeco Lirika One Touch Cappuccino, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0083dddef6bc6503</td>\n",
       "      <td>8f9c8fcf9cb2862c</td>\n",
       "      <td>Lenovo 62A8KAT1EU Монитор. Яркость 250   кд/м²...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>f64cac93254ce4d5</td>\n",
       "      <td>f50c3e7f0b02facb</td>\n",
       "      <td>Видеокарта MSI GeForce RTX 2060 1680Mhz PCI-E ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>f6845400f1cf53d8</td>\n",
       "      <td>25d66337f5007356</td>\n",
       "      <td>Смартфон Samsung Galaxy M52 5G 8/128 ГБ Global...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>f8379ac458f614c1</td>\n",
       "      <td>3506a28b65ac9e2b</td>\n",
       "      <td>Водонагреватель thermex titaniumheat 150v 1110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>f975127890a04b50</td>\n",
       "      <td>35b3667e9c4d5ab3</td>\n",
       "      <td>Водонагреватель thermex surf 5000, 5 квт, с ле...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>f9a708dee74fe3d4</td>\n",
       "      <td>07be2569f73bd6b7</td>\n",
       "      <td>Zanussi ZACS-09 HPR/A18/N1. Класс энергоэффект...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2226 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           product_id      reference_id  \\\n",
       "0    0007302f2fe1d54d  f497219eb0077f84   \n",
       "1    0039af5efceac4ab  28085e941cde1639   \n",
       "2    004f2158acb8165c  9afe55bb4bf1e8a8   \n",
       "3    005cddb29e1677ec  1f21918ceb5d345c   \n",
       "4    0083dddef6bc6503  8f9c8fcf9cb2862c   \n",
       "..                ...               ...   \n",
       "404  f64cac93254ce4d5  f50c3e7f0b02facb   \n",
       "405  f6845400f1cf53d8  25d66337f5007356   \n",
       "406  f8379ac458f614c1  3506a28b65ac9e2b   \n",
       "407  f975127890a04b50  35b3667e9c4d5ab3   \n",
       "408  f9a708dee74fe3d4  07be2569f73bd6b7   \n",
       "\n",
       "                                                merged  \n",
       "0    Классическая сплит-система ROYAL CLIMA PANDORA...  \n",
       "1    Холодильник Бирюса 118. Мощность  замораживани...  \n",
       "2    ASUS TUF-GTX1660S-O6G-GAMING Видеокарта. Объем...  \n",
       "3    Кофемашина Saeco Lirika One Touch Cappuccino, ...  \n",
       "4    Lenovo 62A8KAT1EU Монитор. Яркость 250   кд/м²...  \n",
       "..                                                 ...  \n",
       "404  Видеокарта MSI GeForce RTX 2060 1680Mhz PCI-E ...  \n",
       "405  Смартфон Samsung Galaxy M52 5G 8/128 ГБ Global...  \n",
       "406  Водонагреватель thermex titaniumheat 150v 1110...  \n",
       "407  Водонагреватель thermex surf 5000, 5 квт, с ле...  \n",
       "408  Zanussi ZACS-09 HPR/A18/N1. Класс энергоэффект...  \n",
       "\n",
       "[2226 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train = pd.concat([train_t, val_t])\n",
    "L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train = np.stack([*X_train, *X_val], axis=0)\n",
    "Ly_train = np.stack([*y_train, *y_val], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_train = MyCustomDataset(L_train, Ly_train)\n",
    "arc_train_dl1 = DataLoader(dL_train, 32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name       | Type         | Params\n",
      "--------------------------------------------\n",
      "0 | emb_net    | EmbeddingNet | 10.1 M\n",
      "1 | classifier | ArcLoss      | 241 K \n",
      "--------------------------------------------\n",
      "10.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.4 M    Total params\n",
      "41.423    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 70/70 [00:18<00:00,  3.78it/s, loss=2.47, v_num=50, train_loss=2.100, train_acc=0.969] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_arc = ArcNet(EmbeddingNet(), train_classes=len(encoder.keys()))\n",
    "trainer = pl.Trainer(gpus=0, max_epochs=5)\n",
    "trainer.fit(net_arc, arc_train_dl1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 96.57039711191335%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9657039711191335"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_arc.eval()\n",
    "net_arc.emb_net.to('cpu')\n",
    "knn = train_knn(net_arc.emb_net, is_normalize=True)\n",
    "test_knn(net_arc.emb_net, knn, is_normalize=True) #KNN 1 5ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 96.20938628158845%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9620938628158845"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_arc.eval()\n",
    "net_arc.emb_net.to('cpu')\n",
    "knn = train_knn(net_arc.emb_net, is_normalize=True)\n",
    "test_knn(net_arc.emb_net, knn, is_normalize=True) #KNN 1 10ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 93.32129963898917%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9332129963898917"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_arc.eval()\n",
    "net_arc.emb_net.to('cpu')\n",
    "knn = train_knn(net_arc.emb_net, is_normalize=True)\n",
    "test_knn(net_arc.emb_net, knn, is_normalize=True) #Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net_arc.state_dict(), \"arc_net.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 96.57039711191335%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9657039711191335"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_net = ArcNet(EmbeddingNet(), train_classes=len(encoder.keys()))\n",
    "test_net.load_state_dict(torch.load('arc_net.pth'))\n",
    "test_net.eval()\n",
    "\n",
    "test_net.emb_net.to('cpu')\n",
    "knn = train_knn(test_net.emb_net, is_normalize=True)\n",
    "test_knn(test_net.emb_net, knn, is_normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
